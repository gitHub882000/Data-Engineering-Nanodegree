{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# I94 Immigration Data Lake\n",
    "\n",
    "## Project Summary\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import DoubleType, IntegerType, LongType, StringType, TimestampType\n",
    "from pyspark.sql.functions import col, udf, date_format, upper, to_date, year, month\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.repositories\", \"https://repos.spark-packages.org/\").\\\n",
    "config(\"spark.jars.packages\", \"saurfang:spark-sas7bdat:2.0.0-s_2.11\").\\\n",
    "enableHiveSupport().getOrCreate()\n",
    "\n",
    "# If using S3 bucket\n",
    "# output_key = 's3a://capstone-datalake/'\n",
    "\n",
    "# If testing locally\n",
    "output_key = './datamart/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Step 1: Scope the Project and Gather Data\n",
    "\n",
    "### Scope \n",
    "This project uses three datasources: I94 immigration data, world temperature data and US demographic data to setup a Data Lake with fact and dimension tables.\n",
    "\n",
    "#### Tools and Technologies\n",
    "1. AWS S3 for data storage.\n",
    "2. Pandas to explore and analyze the data.\n",
    "3. PySpark for the main ETL process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Describe and Gather Data \n",
    "\n",
    "#### I94 Immigration Data\n",
    "This data comes from the US National Tourism and Trade Office. [This](https://www.trade.gov/national-travel-and-tourism-office) is where the data comes from.\n",
    "\n",
    "The immigration data is stored in a folder with the following path: `../../data/18-83510-I94-Data-2016/`. There's a file for each month of the year. An example file name is `i94_apr16_sub.sas7bdat`. Each file has a three-letter abbreviation for the month name. So a full file path for June would look like this: `../../data/18-83510-I94-Data-2016/i94_jun16_sub.sas7bdat`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### World Temperature Data\n",
    "This dataset came from this Kaggle [link](https://www.kaggle.com/berkeleyearth/climate-change-earth-surface-temperature-data).\n",
    "\n",
    "The temperature data is stored in a folder with the following path: `../../data2/`. There's just one file in that folder, called `GlobalLandTemperaturesByCity.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### U.S. City Demographic Data\n",
    "This dataset came from this OpenSoft [link](https://public.opendatasoft.com/explore/dataset/us-cities-demographics/export/).\n",
    "\n",
    "The demographic data is just 1 csv file in this folder: `./us-cities-demographics.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Step 2: Explore and Assess the Data\n",
    "### Explore the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### I94 Immigration Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Preview data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'cicid', 'i94yr', 'i94mon', 'i94cit', 'i94res', 'i94port',\n",
       "       'arrdate', 'i94mode', 'i94addr', 'depdate', 'i94bir', 'i94visa',\n",
       "       'count', 'dtadfile', 'visapost', 'occup', 'entdepa', 'entdepd',\n",
       "       'entdepu', 'matflag', 'biryear', 'dtaddto', 'gender', 'insnum',\n",
       "       'airline', 'admnum', 'fltno', 'visatype'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the data here\n",
    "df_immi = pd.read_csv(\"immigration_data_sample.csv\")\n",
    "df_immi.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>i94bir</th>\n",
       "      <th>i94visa</th>\n",
       "      <th>count</th>\n",
       "      <th>dtadfile</th>\n",
       "      <th>visapost</th>\n",
       "      <th>occup</th>\n",
       "      <th>entdepa</th>\n",
       "      <th>entdepd</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2027561</td>\n",
       "      <td>4084316.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>HHW</td>\n",
       "      <td>20566.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HI</td>\n",
       "      <td>20573.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160422</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>07202016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JL</td>\n",
       "      <td>5.658267e+10</td>\n",
       "      <td>00782</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2171295</td>\n",
       "      <td>4422636.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>MCA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TX</td>\n",
       "      <td>20568.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160423</td>\n",
       "      <td>MTR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "      <td>R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>10222016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>*GA</td>\n",
       "      <td>9.436200e+10</td>\n",
       "      <td>XBLNG</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>589494</td>\n",
       "      <td>1195600.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>OGG</td>\n",
       "      <td>20551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>20571.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160407</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1940.0</td>\n",
       "      <td>07052016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LH</td>\n",
       "      <td>5.578047e+10</td>\n",
       "      <td>00464</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2631158</td>\n",
       "      <td>5291768.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20572.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>20581.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160428</td>\n",
       "      <td>DOH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>10272016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>QR</td>\n",
       "      <td>9.478970e+10</td>\n",
       "      <td>00739</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3032257</td>\n",
       "      <td>985523.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>CHM</td>\n",
       "      <td>20550.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>20553.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160406</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Z</td>\n",
       "      <td>K</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>07042016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.232257e+10</td>\n",
       "      <td>LAND</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  \\\n",
       "0     2027561  4084316.0  2016.0     4.0   209.0   209.0     HHW  20566.0   \n",
       "1     2171295  4422636.0  2016.0     4.0   582.0   582.0     MCA  20567.0   \n",
       "2      589494  1195600.0  2016.0     4.0   148.0   112.0     OGG  20551.0   \n",
       "3     2631158  5291768.0  2016.0     4.0   297.0   297.0     LOS  20572.0   \n",
       "4     3032257   985523.0  2016.0     4.0   111.0   111.0     CHM  20550.0   \n",
       "\n",
       "   i94mode i94addr  depdate  i94bir  i94visa  count  dtadfile visapost occup  \\\n",
       "0      1.0      HI  20573.0    61.0      2.0    1.0  20160422      NaN   NaN   \n",
       "1      1.0      TX  20568.0    26.0      2.0    1.0  20160423      MTR   NaN   \n",
       "2      1.0      FL  20571.0    76.0      2.0    1.0  20160407      NaN   NaN   \n",
       "3      1.0      CA  20581.0    25.0      2.0    1.0  20160428      DOH   NaN   \n",
       "4      3.0      NY  20553.0    19.0      2.0    1.0  20160406      NaN   NaN   \n",
       "\n",
       "  entdepa entdepd  entdepu matflag  biryear   dtaddto gender  insnum airline  \\\n",
       "0       G       O      NaN       M   1955.0  07202016      F     NaN      JL   \n",
       "1       G       R      NaN       M   1990.0  10222016      M     NaN     *GA   \n",
       "2       G       O      NaN       M   1940.0  07052016      M     NaN      LH   \n",
       "3       G       O      NaN       M   1991.0  10272016      M     NaN      QR   \n",
       "4       Z       K      NaN       M   1997.0  07042016      F     NaN     NaN   \n",
       "\n",
       "         admnum  fltno visatype  \n",
       "0  5.658267e+10  00782       WT  \n",
       "1  9.436200e+10  XBLNG       B2  \n",
       "2  5.578047e+10  00464       WT  \n",
       "3  9.478970e+10  00739       B2  \n",
       "4  4.232257e+10   LAND       WT  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_immi.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Check if `cicid` is a primary key candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_immi['cicid'].apply(float.is_integer).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_immi['cicid'].duplicated().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Column `cicid` is whole float (integer) and distinct, so `cicid` can be used as a primary key for tables related to `df_immi`. However, I need to convert `cicid` (along with other float columns) to integer first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### World Temperature Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Preview data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['dt', 'AverageTemperature', 'AverageTemperatureUncertainty', 'City',\n",
       "       'Country', 'Latitude', 'Longitude'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the data here\n",
    "df_temp = pd.read_csv(\"../../data2/GlobalLandTemperaturesByCity.csv\")\n",
    "df_temp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47555</th>\n",
       "      <td>1820-01-01</td>\n",
       "      <td>2.101</td>\n",
       "      <td>3.217</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47556</th>\n",
       "      <td>1820-02-01</td>\n",
       "      <td>6.926</td>\n",
       "      <td>2.853</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47557</th>\n",
       "      <td>1820-03-01</td>\n",
       "      <td>10.767</td>\n",
       "      <td>2.395</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47558</th>\n",
       "      <td>1820-04-01</td>\n",
       "      <td>17.989</td>\n",
       "      <td>2.202</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47559</th>\n",
       "      <td>1820-05-01</td>\n",
       "      <td>21.809</td>\n",
       "      <td>2.036</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               dt  AverageTemperature  AverageTemperatureUncertainty     City  \\\n",
       "47555  1820-01-01               2.101                          3.217  Abilene   \n",
       "47556  1820-02-01               6.926                          2.853  Abilene   \n",
       "47557  1820-03-01              10.767                          2.395  Abilene   \n",
       "47558  1820-04-01              17.989                          2.202  Abilene   \n",
       "47559  1820-05-01              21.809                          2.036  Abilene   \n",
       "\n",
       "             Country Latitude Longitude  \n",
       "47555  United States   32.95N   100.53W  \n",
       "47556  United States   32.95N   100.53W  \n",
       "47557  United States   32.95N   100.53W  \n",
       "47558  United States   32.95N   100.53W  \n",
       "47559  United States   32.95N   100.53W  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only take USA data\n",
    "df_temp = df_temp[df_temp['Country'] == 'United States']\n",
    "df_temp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Check if `(dt, City)` is a primary key candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp.duplicated(subset=['dt', 'City']).any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The set of `(dt, City)` is not distinct, we need to clean this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### U.S. City Demographic Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Preview data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['City', 'State', 'Median Age', 'Male Population', 'Female Population',\n",
       "       'Total Population', 'Number of Veterans', 'Foreign-born',\n",
       "       'Average Household Size', 'State Code', 'Race', 'Count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the data here\n",
    "df_demo = pd.read_csv(\"us-cities-demographics.csv\", delimiter=';')\n",
    "df_demo.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601.0</td>\n",
       "      <td>41862.0</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562.0</td>\n",
       "      <td>30908.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129.0</td>\n",
       "      <td>49500.0</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147.0</td>\n",
       "      <td>32935.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040.0</td>\n",
       "      <td>46799.0</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819.0</td>\n",
       "      <td>8229.0</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>California</td>\n",
       "      <td>34.5</td>\n",
       "      <td>88127.0</td>\n",
       "      <td>87105.0</td>\n",
       "      <td>175232</td>\n",
       "      <td>5821.0</td>\n",
       "      <td>33878.0</td>\n",
       "      <td>3.18</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>24437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>34.6</td>\n",
       "      <td>138040.0</td>\n",
       "      <td>143873.0</td>\n",
       "      <td>281913</td>\n",
       "      <td>5829.0</td>\n",
       "      <td>86253.0</td>\n",
       "      <td>2.73</td>\n",
       "      <td>NJ</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               City          State  Median Age  Male Population  \\\n",
       "0     Silver Spring       Maryland        33.8          40601.0   \n",
       "1            Quincy  Massachusetts        41.0          44129.0   \n",
       "2            Hoover        Alabama        38.5          38040.0   \n",
       "3  Rancho Cucamonga     California        34.5          88127.0   \n",
       "4            Newark     New Jersey        34.6         138040.0   \n",
       "\n",
       "   Female Population  Total Population  Number of Veterans  Foreign-born  \\\n",
       "0            41862.0             82463              1562.0       30908.0   \n",
       "1            49500.0             93629              4147.0       32935.0   \n",
       "2            46799.0             84839              4819.0        8229.0   \n",
       "3            87105.0            175232              5821.0       33878.0   \n",
       "4           143873.0            281913              5829.0       86253.0   \n",
       "\n",
       "   Average Household Size State Code                       Race  Count  \n",
       "0                    2.60         MD         Hispanic or Latino  25924  \n",
       "1                    2.39         MA                      White  58723  \n",
       "2                    2.58         AL                      Asian   4759  \n",
       "3                    3.18         CA  Black or African-American  24437  \n",
       "4                    2.73         NJ                      White  76402  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_demo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Check if `(City, State)` is a primary key candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_demo.duplicated(subset=['City', 'State']).any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The set of `(City, State)` is not distinct, we need to clean this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Cleaning Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### I94 Immigration Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Performing cleaning tasks here\n",
    "df_immi = spark.read.format('com.github.saurfang.sas.spark').load('../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat')\n",
    "df_immi = df_immi.withColumn(\"cicid\", df_immi[\"cicid\"].cast(IntegerType())) \\\n",
    "                 .withColumn(\"i94yr\", df_immi[\"i94yr\"].cast(IntegerType())) \\\n",
    "                 .withColumn(\"i94mon\", df_immi[\"i94mon\"].cast(IntegerType())) \\\n",
    "                 .withColumn(\"i94cit\", df_immi[\"i94cit\"].cast(IntegerType())) \\\n",
    "                 .withColumn(\"i94res\", df_immi[\"i94res\"].cast(IntegerType())) \\\n",
    "                 .withColumn(\"arrdate\", df_immi[\"arrdate\"].cast(IntegerType())) \\\n",
    "                 .withColumn(\"depdate\", df_immi[\"depdate\"].cast(IntegerType())) \\\n",
    "                 .withColumn(\"i94mode\", df_immi[\"i94mode\"].cast(IntegerType())) \\\n",
    "                 .withColumn(\"i94visa\", df_immi[\"i94visa\"].cast(IntegerType())) \\\n",
    "                 .withColumn(\"biryear\", df_immi[\"biryear\"].cast(IntegerType())) \\\n",
    "                 .withColumn(\"admnum\", df_immi[\"admnum\"].cast(LongType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# for record in df_immi.head(2):\n",
    "#     print(record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### World Temperature Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Performing cleaning tasks here\n",
    "df_temp = spark.read.option(\"header\", \"true\").csv('../../data2/GlobalLandTemperaturesByCity.csv')\n",
    "df_temp = df_temp.filter(df_temp['Country'] == 'United States')\n",
    "df_temp = df_temp.dropDuplicates(subset=['dt', 'City'])\n",
    "df_temp = df_temp.withColumn(\"AverageTemperature\", df_temp[\"AverageTemperature\"].cast(DoubleType())) \\\n",
    "                 .withColumn(\"AverageTemperatureUncertainty\", df_temp[\"AverageTemperatureUncertainty\"].cast(DoubleType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# for record in df_temp.head(2):\n",
    "#     print(record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### U.S. City Demographic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Performing cleaning tasks here\n",
    "df_demo = spark.read.option(\"header\", \"true\").option(\"delimiter\", \";\").csv('us-cities-demographics.csv')\n",
    "df_demo = df_demo.dropDuplicates(subset=['City', 'State'])\n",
    "df_demo = df_demo.withColumn(\"Male Population\", df_demo[\"Male Population\"].cast(IntegerType())) \\\n",
    "                 .withColumn(\"Female Population\", df_demo[\"Female Population\"].cast(IntegerType())) \\\n",
    "                 .withColumn(\"Number of Veterans\", df_demo[\"Number of Veterans\"].cast(IntegerType())) \\\n",
    "                 .withColumn(\"Foreign-born\", df_demo[\"Foreign-born\"].cast(IntegerType())) \\\n",
    "                 .withColumn(\"Median Age\", df_demo[\"Median Age\"].cast(DoubleType())) \\\n",
    "                 .withColumn(\"Average Household Size\", df_demo[\"Average Household Size\"].cast(DoubleType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# for record in df_demo.head(2):\n",
    "#     print(record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Step 3: Define the Data Model\n",
    "### 3.1 Conceptual Data Model\n",
    "For an OLAP or BI application, it is best to use a Star schema for our data model.\n",
    "\n",
    "<img src=\"./images/datamart.png\" width=\"600\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 3.2 Mapping Out Data Pipelines\n",
    "\n",
    "We have only checked for primary key candidate and filter out some unnecessary data such as `Country` data in `df_temp`. However, we still have a lot of work to transform the raw dataframes into what are designed.\n",
    "\n",
    "1. Rename the columns into what are designed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Step 4: Run Pipelines to Model the Data\n",
    "\n",
    "### 4.1 Create the data model\n",
    "\n",
    "#### Fact Immigration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def parse_i94port(filepath, startline, endline, comma_sep=False):\n",
    "    code_name_dict = {}\n",
    "    \n",
    "    with open(filepath) as file:\n",
    "        file_content = file.readlines()\n",
    "    \n",
    "    for line in file_content[startline:endline]:\n",
    "        code, name = line.split('=')\n",
    "        code, name = code.strip().strip(\"'\"), name.strip().strip(\"'\")\n",
    "        if comma_sep:\n",
    "            name = name.split(',')[0].strip()\n",
    "        code_name_dict[code] = name\n",
    "    \n",
    "    return code_name_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Rename the columns\n",
    "rename_mapping = dict(zip(\n",
    "    ['cicid', 'i94yr', 'i94mon', 'i94port', 'i94addr', 'arrdate', 'depdate',\n",
    "     'i94mode', 'i94visa', 'i94cit', 'i94res', 'biryear', 'gender', 'insnum',\n",
    "     'airline', 'admnum', 'fltno', 'visatype'],\n",
    "    ['cic_id', 'year', 'month', 'city', 'state', 'arrival_date', 'departure_date',\n",
    "     'mode', 'visa', 'citizen_country', 'residence_country', 'birth_year', 'gender',\n",
    "     'ins_num', 'airline', 'admin_num', 'flight_number', 'visa_type']\n",
    "))\n",
    "fact_immi = df_immi.select([col(c).alias(rename_mapping.get(c)) for c in df_immi.columns if c in rename_mapping.keys()])\n",
    "\n",
    "# Map city\n",
    "code_city_mapping = parse_i94port('I94_SAS_Labels_Descriptions.SAS', 302, 962, comma_sep=True)\n",
    "\n",
    "@udf(returnType=StringType())\n",
    "def map_city(code):\n",
    "    return code_city_mapping.get(code, 'other')\n",
    "\n",
    "fact_immi = fact_immi.withColumn('city', map_city(col('city')))\n",
    "\n",
    "# Map state\n",
    "code_state_mapping = parse_i94port('I94_SAS_Labels_Descriptions.SAS', 981, 1036)\n",
    "\n",
    "@udf(returnType=StringType())\n",
    "def map_state(code):\n",
    "    return code_state_mapping.get(code, 'other')\n",
    "\n",
    "fact_immi = fact_immi.withColumn('state', map_state(col('state')))\n",
    "\n",
    "# Process arrival_date\n",
    "fact_immi = fact_immi.withColumn('arrival_date', (col(\"arrival_date\") * 24 * 3600).cast(TimestampType()))\n",
    "fact_immi = fact_immi.withColumn(\"arrival_date\", date_format(col(\"arrival_date\"), \"yyyy-MM-dd\"))\n",
    "\n",
    "# Process arrival_date\n",
    "fact_immi = fact_immi.withColumn('departure_date', (col(\"departure_date\") * 24 * 3600).cast(TimestampType()))\n",
    "fact_immi = fact_immi.withColumn(\"departure_date\", date_format(col(\"departure_date\"), \"yyyy-MM-dd\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(cic_id=6, year=2016, month=4, citizen_country=692, residence_country=692, city='NOT REPORTED/UNKNOWN', arrival_date='2026-04-30', mode=None, state='other', departure_date=None, visa=2, birth_year=1979, gender=None, ins_num=None, airline=None, admin_num=1897628485, flight_number=None, visa_type='B2')\n",
      "Row(cic_id=7, year=2016, month=4, citizen_country=254, residence_country=276, city='ATLANTA', arrival_date='2026-04-08', mode=1, state='ALABAMA', departure_date=None, visa=3, birth_year=1991, gender='M', ins_num=None, airline=None, admin_num=3736796330, flight_number='00296', visa_type='F1')\n",
      "Row(cic_id=15, year=2016, month=4, citizen_country=101, residence_country=101, city='WASHINGTON DC', arrival_date='2026-04-02', mode=1, state='MICHIGAN', departure_date='2026-08-26', visa=2, birth_year=1961, gender='M', ins_num=None, airline='OS', admin_num=666643185, flight_number='93', visa_type='B2')\n",
      "Row(cic_id=16, year=2016, month=4, citizen_country=101, residence_country=101, city='NEW YORK', arrival_date='2026-04-02', mode=1, state='MASSACHUSETTS', departure_date='2026-04-24', visa=2, birth_year=1988, gender=None, ins_num=None, airline='AA', admin_num=92468461330, flight_number='00199', visa_type='B2')\n",
      "Row(cic_id=17, year=2016, month=4, citizen_country=101, residence_country=101, city='NEW YORK', arrival_date='2026-04-02', mode=1, state='MASSACHUSETTS', departure_date='2026-04-24', visa=2, birth_year=2012, gender=None, ins_num=None, airline='AA', admin_num=92468463130, flight_number='00199', visa_type='B2')\n"
     ]
    }
   ],
   "source": [
    "for record in fact_immi.head(5):\n",
    "    print(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Write code here\n",
    "fact_immi.write.mode('overwrite').partitionBy('year', 'month').parquet(output_key + 'fact_immi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Dim Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Rename the columns\n",
    "rename_mapping = dict(zip(\n",
    "    ['dt', 'City', 'AverageTemperature', 'AverageTemperatureUncertainty'],\n",
    "    ['dt', 'city', 'avg_temp', 'avg_temp_uncertainty']\n",
    "))\n",
    "dim_temp = df_temp.select([col(c).alias(rename_mapping.get(c)) for c in df_temp.columns if c in rename_mapping.keys()])\n",
    "\n",
    "# Convert city to uppercase\n",
    "dim_temp = dim_temp.withColumn('city', upper(col('city')))\n",
    "\n",
    "# Extract month and year\n",
    "dim_temp = dim_temp.withColumn('ts', to_date(col('dt'),'yyyy-MM-dd')) \\\n",
    "                   .withColumn('year', year(col('ts'))) \\\n",
    "                   .withColumn('month', month(col('ts'))) \\\n",
    "                   .drop('ts')\n",
    "\n",
    "# Take only April to match Fact table\n",
    "dim_temp = dim_temp.filter(col('month') == 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(dt='1745-04-01', avg_temp=10.864, avg_temp_uncertainty=1.432, city='ARLINGTON', year=1745, month=4)\n",
      "Row(dt='1745-04-01', avg_temp=5.973000000000001, avg_temp_uncertainty=1.005, city='LOWELL', year=1745, month=4)\n",
      "Row(dt='1746-04-01', avg_temp=None, avg_temp_uncertainty=None, city='LEXINGTON FAYETTE', year=1746, month=4)\n",
      "Row(dt='1749-04-01', avg_temp=None, avg_temp_uncertainty=None, city='VIRGINIA BEACH', year=1749, month=4)\n",
      "Row(dt='1750-04-01', avg_temp=7.822999999999999, avg_temp_uncertainty=1.08, city='HARTFORD', year=1750, month=4)\n"
     ]
    }
   ],
   "source": [
    "for record in dim_temp.head(5):\n",
    "    print(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Write code here\n",
    "dim_temp.write.mode('overwrite').partitionBy('year', 'month').parquet(output_key + 'dim_temp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Dim Demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Rename the columns\n",
    "rename_mapping = dict(zip(\n",
    "    ['City', 'State', 'Male Population', 'Female Population', 'Number of Veterans',\n",
    "     'Foreign-born', 'Median Age', 'Average Household Size'],\n",
    "    ['city', 'state', 'male_population', 'female_population', 'num_veterans',\n",
    "     'foreign_born', 'median_age', 'avg_household_size']\n",
    "))\n",
    "dim_demo = df_demo.select([col(c).alias(rename_mapping.get(c)) for c in df_demo.columns if c in rename_mapping.keys()])\n",
    "\n",
    "# Convert city to uppercase\n",
    "dim_demo = dim_demo.withColumn('city', upper(col('city')))\n",
    "\n",
    "# Convert state to uppercase\n",
    "dim_demo = dim_demo.withColumn('state', upper(col('state')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(city='CINCINNATI', state='OHIO', median_age=32.7, male_population=143654, female_population=154883, num_veterans=13699, foreign_born=16896, avg_household_size=2.08)\n",
      "Row(city='KANSAS CITY', state='KANSAS', median_age=33.4, male_population=74606, female_population=76655, num_veterans=8139, foreign_born=25507, avg_household_size=2.71)\n",
      "Row(city='LYNCHBURG', state='VIRGINIA', median_age=28.7, male_population=38614, female_population=41198, num_veterans=4322, foreign_born=4364, avg_household_size=2.48)\n",
      "Row(city='AUBURN', state='WASHINGTON', median_age=37.1, male_population=36837, female_population=39743, num_veterans=5401, foreign_born=14842, avg_household_size=2.73)\n",
      "Row(city='DAYTON', state='OHIO', median_age=32.8, male_population=66631, female_population=73966, num_veterans=8465, foreign_born=7381, avg_household_size=2.26)\n"
     ]
    }
   ],
   "source": [
    "for record in dim_demo.head(5):\n",
    "    print(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Write code here\n",
    "dim_demo.write.mode('overwrite').parquet(output_key + 'dim_demo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 4.2 Data Quality Checks\n",
    "After each processing steps, it is obvious that I always print out and make sure everything is done perfectly. Therefore, the data quality check can be as simple as just re-read the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Fact Immigration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(cic_id=5748517, citizen_country=245, residence_country=438, city='LOS ANGELES', arrival_date='2026-05-01', mode=1, state='CALIFORNIA', departure_date='2026-05-09', visa=1, birth_year=1976, gender='F', ins_num=None, airline='QF', admin_num=94953870030, flight_number='00011', visa_type='B1', year=2016, month=4),\n",
       " Row(cic_id=5748518, citizen_country=245, residence_country=438, city='LOS ANGELES', arrival_date='2026-05-01', mode=1, state='NEVADA', departure_date='2026-05-18', visa=1, birth_year=1984, gender='F', ins_num=None, airline='VA', admin_num=94955622830, flight_number='00007', visa_type='B1', year=2016, month=4)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform quality checks here\n",
    "spark.read.parquet(output_key + 'fact_immi').head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Dim Temperature\n",
    "\n",
    "If you see no output in `temp` data, it's because the machine has no memory left instead of the code fault."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(dt='1933-04-01', avg_temp=8.173, avg_temp_uncertainty=0.304, city='ALBUQUERQUE', year=1933, month=4),\n",
       " Row(dt='1933-04-01', avg_temp=19.369, avg_temp_uncertainty=0.26899999999999996, city='GAINESVILLE', year=1933, month=4)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform quality checks here\n",
    "spark.read.parquet(output_key + 'dim_temp').head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Dim Demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(city='AMES', state='IOWA', median_age=23.0, male_population=33814, female_population=31238, num_veterans=2265, foreign_born=8606, avg_household_size=2.16),\n",
       " Row(city='BIRMINGHAM', state='ALABAMA', median_age=35.6, male_population=102122, female_population=112789, num_veterans=13212, foreign_born=8258, avg_household_size=2.21)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform quality checks here\n",
    "spark.read.parquet(output_key + 'dim_demo').head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 4.3 Data dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Fact Immigration\n",
    "* `cic_id (Integer)`: CIC ID\n",
    "* `year (Integer)`: immigration year\n",
    "* `month (Integer)`: immigration month\n",
    "* `city (String)`: uppercase immigration destination city\n",
    "* `state (String)`: uppercase immigration destination state\n",
    "* `mode (Integer)`: traffic method\n",
    "* `visa (Integer)`: VISA category\n",
    "* `arrival_date (String)`: arrival date\n",
    "* `departure_date (String)`: departure date\n",
    "* `citizen_country (String)`: country of citizenship\n",
    "* `residence_country (String)`: country of residence\n",
    "* `birth_year (Integer)`: birth year\n",
    "* `gender (String)`: 1 character, 'M' or 'F'\n",
    "* `ins_num (Integer)`: INS number\n",
    "* `airline (String)`: airline used to arrive in USA\n",
    "* `admin_num (Long)`: admission number\n",
    "* `flight_num (Integer)`: flight number\n",
    "* `visa_type (Integer)`: class of legal immigration admission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Dim Temperature\n",
    "* `dt (Timestamp)`: temperature date in format `YYYY-MM-dd`\n",
    "* `city (String)`: uppercase temperature city\n",
    "* `avg_temp (Double)`: Average temperature\n",
    "* `avg_temp_uncertainty (Double)`: Average temperature uncertainty\n",
    "* `year (Integer)`: temperature year extracted from `dt`\n",
    "* `month (Integer)`: temperature month extracted from `dt`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Dim Demographics\n",
    "* `city (String)`: uppercase demographics city\n",
    "* `state (String)`: uppercase demographics state\n",
    "* `male_population (Integer)`: city male population\n",
    "* `female_population (Integer)`: city female population\n",
    "* `num_veterans (Integer)`: number of veterans\n",
    "* `foreign_born (Integer)`: number of foreign-born babies\n",
    "* `median_age (Double)`: city median age\n",
    "* `avg_household_size (Double)`: city average household size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Step 5: Complete Project Write Up\n",
    "\n",
    "#### Tools and Technologies\n",
    "1. AWS S3 for data storage seems to be the best choice for storing Data Lake.\n",
    "2. Pandas to explore and analyze the data as it is very good with small scale datasets (we only analyze with a small proportion of data).\n",
    "3. PySpark for the main ETL process since this requires enormous processing power.\n",
    "\n",
    "#### Data Update Frequency\n",
    "1. Since the data is distributed and loaded to the system by month, the pipeline should be scheduled monthly to build `Fact Immigration` and `Dim Temperature`.\n",
    "2. `Dim Demographics` can be updated annually since it is not that necessary to update demographic data realtime.\n",
    "3. All tables should be updated in an `append-only` mode.\n",
    "\n",
    "#### Future Design Considerations\n",
    "1. The data was increased by 100x.\n",
    "    If Spark with standalone server mode can not process 100x data set, we could consider using [AWS EMR](https://us-west-2.console.aws.amazon.com/elasticmapreduce/home?region=us-west-2#) for processing, yet still use [AWS S3](https://s3.console.aws.amazon.com/s3/get-started?region=us-west-2) for storage.\n",
    "\n",
    "2. The data populate a dashboard that must be updated on a daily basis by 7am every day.\n",
    "    [Apache Airflow](https://airflow.apache.org) could be used for building a data pipeline to regularly update the data which populate the dashboard.\n",
    "\n",
    "3. The database needed to be accessed by 100+ people.\n",
    "    [AWS Redshift](https://us-east-1.console.aws.amazon.com/redshiftv2/home?region=us-east-1#landing) can handle up to 500 connections. Therefore, Redshift should find it easy to handle a workload of 100+ connections at a point of time.\n",
    "    \n",
    "In general, when it comes to scaling the pipeline, the most feasible and efficient solution seems to be *cloudify* it. This could be done using AWS, Microsoft Azure or any trustworthy Cloud service platform. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
